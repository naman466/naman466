<h1 align="center">Hi, I'm Naman Tyagi!</h1>
<p align="center">
  <b>CS student Â· ML systems Â· numerical foundations Â· efficiency research</b>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Focus-ML%20Systems-blue" />
  <img src="https://img.shields.io/badge/Interest-Model%20Efficiency-green" />
  <img src="https://img.shields.io/badge/Learning-Low%20Level%20ML-orange" />
  <img src="https://img.shields.io/badge/Languages-C++%20%7C%20Python-lightgrey" />
</p>

---

I am a computer science student who believes that **deep understanding comes from building things yourself**.  
Instead of only using high level libraries, I explore the layers beneath, from IEEE 754 floating point to compiler IRs and kernel execution.

My goal is to contribute to research in **efficient deep learning** and **low level ML infrastructure**.  
Right now, I am in the learning phase, and every project is an excuse to pull back the curtain.

---

## ğŸ” What I work on

**ğŸ§® Numerical foundations**  
I implement numerical computing concepts from scratch to understand how numbers behave in hardware and why that matters for neural networks.  
â†’ [`numerical-methods`](https://github.com/naman466/numerical-methods) â€“ IEEE 754 (FP32, bfloat16), rounding, overflow, NaNs, precision tradeoffs.

**âš™ï¸ Compiler style lowering**  
I am exploring how a high level model graph (ONNX) can be lowered into executable C code, essentially a miniature ML compiler built for learning.  
â†’ [`null`](https://github.com/naman466/null) â€“ graph traversal, IR design, operation lowering, code generation.

**ğŸ“‰ Model efficiency**  
Alongside systems work, I study sparsity, pruning, quantization, and optimisation with the aim of making models smaller and faster without sacrificing accuracy.  
More projects coming as I deepen this direction.

---

## ğŸ§­ Research interests

- Model efficiency and compression  
- Low level optimisation for deep learning  
- Numerical behaviour of neural networks  
- ML systems and compiler style execution  

I actively read systems and efficiency papers and build small prototypes to test ideas in practice.  
Long term, I hope to contribute to the ML systems research community.

---

## ğŸš€ Currently learning

- Writing custom Triton kernels  
- MLIR dialect basics  
- Performance profiling with Nsight and perf  
- Sparse computation patterns  

---

## ğŸ“« Find me

- [Personal site or blog](https://naman466.github.io/)  
- [Twitter](https://x.com/naman466)  
- [LinkedIn](https://www.linkedin.com/in/naman466/)
- [Google Scholar](https://scholar.google.com/citations?user=j5IBsvAAAAAJ&hl=en)

---

<p align="center">
  <i>"What I cannot create, I do not understand." â€“ Richard Feynman</i>
</p>
